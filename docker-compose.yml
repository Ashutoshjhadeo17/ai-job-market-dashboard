version: "3.9"

services:

  # ====================================================
  # PIPELINE SERVICE
  # Continuous ingestion → cleaning → spark analytics
  # ====================================================
  pipeline:
    build:
      context: .
      dockerfile: docker/Dockerfile.pipeline

    container_name: ai_job_pipeline

    volumes:
      - ./data:/app/data
      - ./output:/app/output

    environment:
      APP_ENV: prod
      REQUEST_TIMEOUT: 30

    # -------------------------------
    # RESOURCE LIMITS (IMPORTANT)
    # -------------------------------
    mem_limit: 2g
    cpus: 2.0

    restart: unless-stopped


  # ====================================================
  # DASHBOARD SERVICE
  # Streamlit UI reading processed outputs
  # ====================================================
  dashboard:
    build:
      context: .
      dockerfile: docker/Dockerfile.dashboard

    container_name: ai_job_dashboard

    ports:
      - "8501:8501"

    volumes:
      - ./data:/app/data
      - ./output:/app/output

    environment:
      APP_ENV: prod
      TOP_N_RESULTS: 20
      DASHBOARD_REFRESH_SECONDS: 300

    depends_on:
      - pipeline

    # Dashboard is lightweight
    mem_limit: 512m
    cpus: 1.0

    restart: unless-stopped
